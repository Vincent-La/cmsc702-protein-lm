{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, EsmForProteinFolding\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.esm_inference import SequenceDataset\n",
    "from utils.model_names import ESM_FOLD, ESM_CONTACT_HEAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_file = '/nfshomes/vla/cmsc702-protein-lm/results/cadherin/PF00028_10000_msa_trimmed.faa'\n",
    "esmfold_tokenizer = AutoTokenizer.from_pretrained(ESM_FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(msa_file)\n",
    "eval_dataloader = DataLoader(dataset, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches = []\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    all_batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(all_batches):\n",
    "\n",
    "    try:\n",
    "        inputs = esmfold_tokenizer(\n",
    "            batch,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "    except:\n",
    "        print(f'BAD BATCH:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHVKVKETHVIGQTAFXVKATDADSGSNGRVSYQIQTRNDBGFFKLMPDTGEVKLLKSLDMEVLKEVNWNRTLVIAXSDHGIPSLSSNASFVISVE\n"
     ]
    }
   ],
   "source": [
    "for seq in all_batches[98]:\n",
    "    try:\n",
    "        inputs = esmfold_tokenizer(\n",
    "            [seq],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "    except:\n",
    "        print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_alphabet = 'ARNDCEQGHILKMFPSTWYV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "B\n",
      "X\n"
     ]
    }
   ],
   "source": [
    "for let in 'NHVKVKETHVIGQTAFXVKATDADSGSNGRVSYQIQTRNDBGFFKLMPDTGEVKLLKSLDMEVLKEVNWNRTLVIAXSDHGIPSLSSNASFVISVE':\n",
    "    if let not in AA_alphabet:\n",
    "        print(let)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 SAEPGHLVTKIVAVDRDSGXNAWLSYHLLKASEPGLFKVEVHTGEVRTARSLQDRDALKQSLVVAVQNHSQPPLSATVTLTVAV X\n",
      "624 PVLEDAPRGTVIALISVSDGDSGANGQVTCTLTHHVPFKLVSTFKNYYSLMLDSALDRESMANYEVVVTARDGGSPSLSATAX X\n",
      "624 VLPSTLPGTSITEVYAVDKDTGMNAVIAYSIIKRKGGXPGSFDIDPDTGNITLKRELSDRGLYSLLVKVSDHGQPEPLHSTVLVNLFV X\n",
      "624 LNIPLNSRVNSTIFTAVAYDGDRDANGAVRYXIVSXNDKNFFHMDLSSGXLKLAKSLEDLETHDLQIQARDLGRRIKKSSINVKIMV X\n",
      "624 LNIPLNSRVNSTIFTAVAYDGDRDANGAVRYXIVSXNDKNFFHMDLSSGXLKLAKSLEDLETHDLQIQARDLGRRIKKSSINVKIMV X\n",
      "624 LNIPLNSRVNSTIFTAVAYDGDRDANGAVRYXIVSXNDKNFFHMDLSSGXLKLAKSLEDLETHDLQIQARDLGRRIKKSSINVKIMV X\n",
      "624 IVISVEENVPVGTLVYAFNARDGDGSFLNSRIQYFAESSHVGMNPFLIHPSSGTLVTASPLDRENVPTFILTITAXDQA X\n",
      "624 VLEIPENSPVGAVFLLESATDLDVGTNAVKNYVISXNSHFHITTRVNPEGRKYPELVLDKVLDYEEQPELSLILTALDGGTPPRSGTALVRVEV X\n",
      "624 GSANVYENSNGALVGVLATTDEDASQTFTYTLTNDXSGRFVVRGDKLFVSNSANLDFEKQSLYSVSIQSTDSGSPSLKH X\n",
      "624 XLVAKVVAVDADSGQNAWLSYELAKATEPGLFRVGLHNGEVRTARAVSERDAARQRLVVLVRDSGQPPRSSTVTLSL X\n",
      "624 AITVSQNTQPGMVLFIAHAHDHDSGANGRVQYYLKSSQNGTFAIDANLGTVTLNQTLGVRHPRWYNLEIVAKDEGEPPLSSXLTLSVYV X\n",
      "624 YNFTVMESDKVTEIVGVVSVQPSNIPLWFDIVGGNYDSSFDAEKGVGTIVIAKPLDAEQRSXYNMTVEVTDGTNXATTQVLIKVL X\n",
      "624 YNFTVMESDKVTEIVGVVSVQPSNIPLWFDIVGGNYDSSFDAEKGVGTIVIAKPLDAEQRSXYNMTVEVTDGTNXATTQVLIKVL X\n",
      "624 NHVKVKETHVIGQTAFXVKATDADSGSNGRVSYQIQTRNDBGFFKLMPDTGEVKLLKSLDMEVLKEVNWNRTLVIAXSDHGIPSLSSNASFVISVE X\n",
      "624 NHVKVKETHVIGQTAFXVKATDADSGSNGRVSYQIQTRNDBGFFKLMPDTGEVKLLKSLDMEVLKEVNWNRTLVIAXSDHGIPSLSSNASFVISVE B\n",
      "624 NHVKVKETHVIGQTAFXVKATDADSGSNGRVSYQIQTRNDBGFFKLMPDTGEVKLLKSLDMEVLKEVNWNRTLVIAXSDHGIPSLSSNASFVISVE X\n",
      "624 YVFSVQEGKANQTVVNQVLATDKDEGSNAKLTYAFESVVREFVIDKDTGVIKTNKVLDRERKPSYFITVVATDGGVSSRVDKTLVTIXIE X\n",
      "624 YHFTVLEDIAVGESIGRVXANDLDIGENAKSSYDIIEGDGVDIFEITSDSQTQEGIIRLRKPLDFETKRSYTLKVEATNAHIDPR X\n",
      "624 LSVVEEEANAFVGQVRAXDPDAGINGQVHYSLGNFNNLFRITSNGSIYTAVKLNREVRDYYELVVVATDGAVHPRHSTLTLAIKVL X\n",
      "624 YVIHVPENNQPGASIAQVSASDSDLGPNGQGSYWIAAGDGEPRALSSYVSVSAQSGVVLAQRAFXHERLRAFELTLQAGDPRVICAEGSPALSAHVSLRVLV X\n",
      "624 DLEICESALPGXKFLLDSAQDADVESNSLKIYSISHNEHFSLSTKESPNGSKYPELLLEKSLDREQQSSHHLILTAMDGGDPPLSSTTQIRTQVT X\n",
      "624 YEITILESEPVNSRFFKVQASDKDSGVNGEIAYSIIEGNTGDAFGIFPDGQLYIKSELDRELQERYILLVXASDRAVEPLNATVNVTVIL X\n",
      "624 KVLENAXIDTLIGQFSARDEDVSQTLTFSLMDDDNGRFRVDSSGKLYKAKGTNYEAQKTHSIRAVVTDNGSPAMKMEKTFIIEVL X\n",
      "624 YTVNISEEVPLGSYVRGLSATDRDSGLNANLKYSIVSGXELGWFRISEHSGLVTTAGPEGATAGHAAGMSTSSRLDRETATQVVLNISARDQGVQPRFSYAQLVVTIL X\n",
      "624 AGRLVGKIRAVDADSGYNAWLRYELXDLTGGPWQVGLHNGEISTRHTLQEADGSSSQTVLVLVKDHGXPPRSATATLTVSL X\n",
      "624 AGRLVGKIRAVDADSGYNAWLRYELXDLTGGPWQVGLHNGEISTRHTLQEADGSSSQTVLVLVKDHGXPPRSATATLTVSL X\n",
      "624 YVVQVPEDTPSGSSIARVRAVDRDTGSAGSVTYFLKXPHPTEFSVDRHSGVLRLXAGAILDFEKARAHFVTVVAKDGGGKLRGADVVLSATTVVTVNVE X\n",
      "624 YVVQVPEDTPSGSSIARVRAVDRDTGSAGSVTYFLKXPHPTEFSVDRHSGVLRLXAGAILDFEKARAHFVTVVAKDGGGKLRGADVVLSATTVVTVNVE X\n",
      "624 YHVHVREDFPVGNYITSVSAYDYDAGTNADITYSIASGNDKGHFQLQGKTGSIQLIRALDYKDATXFNLTVQASDGG X\n",
      "624 YAAQLPESLXVGSEVLSVSALTRDGGGPDHVKYRIVSGNEDGRFLLDPQSGLLTLVFPLDFEAHREYYLSVEGSRGRSSLTDVTTVFINVT X\n",
      "624 TLLVHENNXPALHIGSVSATDRDSGTNAQITYSLLPNQDPHLPLXSLVSINADNGQLFALRALDFEALQXFEFXVGATDQGSPALSSQALVRVVVL X\n",
      "624 TLLVHENNXPALHIGSVSATDRDSGTNAQITYSLLPNQDPHLPLXSLVSINADNGQLFALRALDFEALQXFEFXVGATDQGSPALSSQALVRVVVL X\n",
      "624 TLLVHENNXPALHIGSVSATDRDSGTNAQITYSLLPNQDPHLPLXSLVSINADNGQLFALRALDFEALQXFEFXVGATDQGSPALSSQALVRVVVL X\n",
      "624 TLLVHENNXPALHIGSVSATDRDSGTNAQITYSLLPNQDPHLPLXSLVSINADNGQLFALRALDFEALQXFEFXVGATDQGSPALSSQALVRVVVL X\n",
      "624 FXVTVNEDATTGFEVTDXTATDLDSGANGQVTYSILSGNDLGFFVIEGSKVKVAKNLDLETQSHNSNTSYSLTVYATDKGTPPLNNSVSVDITVL X\n",
      "624 FXVTVNEDATTGFEVTDXTATDLDSGANGQVTYSILSGNDLGFFVIEGSKVKVAKNLDLETQSHNSNTSYSLTVYATDKGTPPLNNSVSVDITVL X\n",
      "624 DTIPEDALPGKLIMQVSATDADIRSNAEITYTLFGSGAEKFKLNPDTGELKTLAPLDREEQAVYNLLVKATDGGGRFCQAXVVLT X\n",
      "624 YHIHVKESISVGSHITEVSANDCDAGTNAEVTYXIISGNXRGHFRLDGKTGSVDLMKPLDYEDTIKFTLVIQATDAGA X\n",
      "624 YHIHVKESISVGSHITEVSANDCDAGTNAEVTYXIISGNXRGHFRLDGKTGSVDLMKPLDYEDTIKFTLVIQATDAGA X\n",
      "624 ELRMSETTAPGSRHLLPEAHDPDSGLNSLQRYELSGDEHFSLAVXAGPGGDQRPELVLAKALDRXEAAYHELVLRASDGGEPARTGTARLRVMVL X\n",
      "624 ELRMSETTAPGSRHLLPEAHDPDSGLNSLQRYELSGDEHFSLAVXAGPGGDQRPELVLAKALDRXEAAYHELVLRASDGGEPARTGTARLRVMVL X\n",
      "624 YSASIDENXSIGTNVVQTSAXDEDGDTVTYAISGSSHFSITSNGMIKTASALDFETTNSYSLTVTFGDGTTTSSKAVTVTV X\n",
      "624 YSASIDENXSIGTNVVQTSAXDEDGDTVTYAISGSSHFSITSNGMIKTASALDFETTNSYSLTVTFGDGTTTSSKAVTVTV X\n",
      "624 RTGDLLQMVKAVDVDFGNNSVIDYEXTVVNETDSCQANFSITSNGSIYSTVDLKENCQYTLLVEARDRGVPSRAGECHVIIRV X\n",
      "624 LTAHLLENCPPGFSVLQVTATDQDSGLNGELVYRIEAGAQDRFLVHPVTGVIRVGNATIDREEQEAYRLTVVATDRXTVPLSGTAIITILI X\n",
      "624 YTVCVPENLPPGTVFLQIEAKDVDLGANVTYXIRTQEALQYFALNKYTGELSLLKSLDYESFSDTEATFTFLVEAFDSKGTMPPGLATVTVRI X\n",
      "624 YEFYVXENTQMGITVGDVKAKSFSGVKLWYEILQGNDNGKFVLDSNTGSLTLPNPLDYERDSNIYHLKIKASETAITPSFNSAVTVKIY X\n",
      "624 LTIPEHSSIGTSYKIHSATDKDVGINSIQSYNIVPENGPFGLNVTKTLDGSFFVRVVIRQTLDREXQNYYQLNIRAWMGVHPQCGVLTVHVDV X\n",
      "624 YKASFDENVPIGTTVMSVSAVDPDEGENGYVTYSIANLNHVPFXINHFTGAVSTSENLDYELMPRVYTLRIRASDWGSPYRR X\n",
      "624 NIIENALSGDRFPLPVANDADVXSNTVKSYKLSPNEHFSLDVQSGAEQSVSAELVLQKALDREKQPVIHLLLTAVDGGKPPRSGTLQITVNVL X\n",
      "624 YMVHIAENKLPGVSIAQVRASDSDLGPNEQVSYSIVVSDLEPRALLSYMSVSAQSGVVFAQRAFHHEQLHAFQLTLQTRDHGSPXANVSLQV X\n",
      "624 KASVEENRPLGTPVLRVSALDPDTGEAGRLHYTMAALXDSRSDGLFAMDPVTGAITTAAPLDRESKSTHVFRVTATDHGTPRRSAMATVTVTVT X\n",
      "624 YEVQVPEXSPLNAXVVTVSARDLDVGPYGNVIYSLFQGGGVSQPFVIDEVTGEIRLSKQLDFEVXQYYNVEIAATDGGGLSGKCTMAVQVL X\n",
      "624 YEVQVPEXSPLNAXVVTVSARDLDVGPYGNVIYSLFQGGGVSQPFVIDEVTGEIRLSKQLDFEVXQYYNVEIAATDGGGLSGKCTMAVQVL X\n",
      "624 YEVQVPEXSPLNAXVVTVSARDLDVGPYGNVIYSLFQGGGVSQPFVIDEVTGEIRLSKQLDFEVXQYYNVEIAATDGGGLSGKCTMAVQVL X\n",
      "624 YHADVPEGKTQDNILRLKVEDKDSPQTPAWRVKYIIKKGNERGNFAIVTDPKTNEGVLSVIKPLVYSTPSXRRLLIVVKNEESFFICQRGFVSVIDSPKLSEMSVSINI X\n",
      "624 YRVQIPEDSPIGFLIVTVSAXDVDLGVNGEVSYSLFQASDEISKTFAINPLTGEIRLKEQLDFERVESYEVNIEARDAGSFTGKCVVLIQV X\n",
      "624 ETPLPVYRLIASXRDQGQNSQITYTIEEEEEGIFTINPTTGMVFSRKAFPASEYNILTVKATDGGSPPLSSHVRLHI X\n",
      "624 YRVQLREDAPXGTLVVKLNASDPDEGSNGELRYSLSSYTSDRERQLFSIDATTGEVRVSGTLDYEESSSYQIYVQATDRGPVPMAGHCKVLVDI X\n",
      "624 XESSLTGSRFPLEGASDADVGSNAQLSYTLSPSEHFTLDVKSSDDNRKSLFLVLAKSLDRETLPVHRLVLTASDGGRPSLTGTMELVISVL X\n",
      "624 RSTDKGSLVAKVIALDTDSVHNSRITYQFLQVTDASLFSLDQYNGEIRTMRMFSTYHXSRHHRLVVVAKDNGEPALSATVTIK X\n",
      "624 FRFVIIENLPPGSSVGTVTARAPDNTKTKDIIYSLVGNXGVFAIDAKSGHITTRILLDREALMKETGDNDYIMRAEAVYNDTTLRRDSAIVIVTV X\n",
      "624 YLNVSEEAPVGTTVGKLLAEDSDIGENAAMNYFIEGDSSDVFGIITDNETQEGTILLKXQVDYESKRKHSVRVKVVNRYIDDRFLKEGPFEDTTIVQISVE X\n",
      "624 YEASLPENSPIGTVVITVSATDADEGVNGDVTYDFGHVSENVKNVFGLDHKTGELKLISEIDFEMVATYDXRIKAKDGLGLSSYTKVTVHVT X\n",
      "624 XPVPEDVESGAVIALIKVHDRDSGDNGEITCHLKELLPFQIVSSSDNYFKLLVDGPVDRERTPEYNITIIATDKGTPPLSTYKTILIEI X\n",
      "624 YEVSVSENIPKWSTICTVSATDLDEXINGDIKFSFQKITKGDSQNLALNSTTGDIILVGNLDYEESQLYEIEIQAKDGGGLSNKSKVMI X\n",
      "624 LVDVNETEPVGQVIARVKAVDLDTGMNGRVKYFIXSGNTDRXFTIDENTGDIKLEKTLDLESKQQPPLHFTLGIQSTDSGSPKLRSNTTMFTINV X\n",
      "624 LVDVNETEPVGQVIARVKAVDLDTGMNGRVKYFIXSGNTDRXFTIDENTGDIKLEKTLDLESKQQPPLHFTLGIQSTDSGSPKLRSNTTMFTINV X\n",
      "624 DSITVSQNTLPGTVLFIAHAHDHDSGANGRVQYHLKTPRNGTXXXXHNLGTVTLNQSLKVDHQQRYKLEIIAKDEGEPSLSSTLTLAVNV X\n",
      "624 DSITVSQNTLPGTVLFIAHAHDHDSGANGRVQYHLKTPRNGTXXXXHNLGTVTLNQSLKVDHQQRYKLEIIAKDEGEPSLSSTLTLAVNV X\n",
      "624 DSITVSQNTLPGTVLFIAHAHDHDSGANGRVQYHLKTPRNGTXXXXHNLGTVTLNQSLKVDHQQRYKLEIIAKDEGEPSLSSTLTLAVNV X\n",
      "624 DSITVSQNTLPGTVLFIAHAHDHDSGANGRVQYHLKTPRNGTXXXXHNLGTVTLNQSLKVDHQQRYKLEIIAKDEGEPSLSSTLTLAVNV X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 SIPENTNVGTLXXXXXXXXXXXXXXYELMAGPEAQELFGLQVAEDQDEKQPQLIVMGNLDREQWDSYDLTIKVQDGGNPPRASSALLRITIL X\n",
      "624 LTVEENIGDGSKILQLTAMDADEGANALVTYTIISGADDSFHIDPESGDLIATKRLDRERRSKYSLLVRADXGLQSSDMRINITV X\n",
      "624 TYIPENTPIDTIVFKAQATDPDSGPNSYIXPLGKKFSIGTIDGEVRLTGELDREEVSNYTLTVVATDKGQPALSSSTEVVVMVL X\n",
      "624 SSSVSEDAXPSTAITLCSLRGEDLGPNDKVICSMSSGGPFKLKASFDNYYSLLTEGPLDRKQVSEYQVLITASDSGSPPLSTGRTLTVFV X\n",
      "624 SSIPENSPETVVAVFSASDPDSGENGKMISSIQNDLPFLLKPTFKNCHTLVXERPLDGEERARYITITVNDTGTPRVKTEHNITVLV X\n",
      "624 YLIEVDEDAKEGSIIGQVVAQDPDIAKNXYSVDRHTDLDRIFNIYSGNGSLFLSKPLDREETPWHNITVIATEINNPKQSSQIPIPVF X\n",
      "624 PCSLMENSLGPFPQHVQQVQPDAAQNYTIFYSISGPGVDKEPLNLFFINKDTGDIFCIXNIDCEQYQEFLIYIYATTVDGYAPEYPLTLLFKV X\n",
      "624 YYXEVSEAAPRGTAVGEVFASDRDMGADGEVHYLIFGNSRKKGFQIHKMTGQIYVSGLLDREKEERVSLKVLAKNFGSIRGADVDEVTVNITVL X\n",
      "624 ISVNVGEDAPIGQSVARVSATDQDGPGPNGKVSYYILNGNQGGLFKINSENGVXSVAKALDYDILPNIHLLNVSARDSGLHYREATTILTVQL X\n",
      "624 YKVSLRENSPPGTLVLKVKATDQDEGISAEITYSFKTLXDIANMFVLDHQRGEIKSKGPIDFESSSSYTISIXGQDGGSIATECKIILK X\n",
      "624 YKVSLRENSPPGTLVLKVKATDQDEGISAEITYSFKTLXDIANMFVLDHQRGEIKSKGPIDFESSSSYTISIXGQDGGSIATECKIILK X\n",
      "624 LVPENTTIGVPIIRLLADDKDEGANAAITYSLGNETTSSGARSRRYDATSRRYFHLDPRTAEISVARSLPPXKNIRLLVLARDSDGLTDNITVRVHVT X\n",
      "624 YHISISENISIGERLLTFSAVDSDRVPNNXYVEYDIIGGNGGSKFHVEKSIIGPKSPGEVVGNLVLRSNLDREGCPSYQLIILASDHGSPXLTSTATISITVL X\n",
      "624 YHISISENISIGERLLTFSAVDSDRVPNNXYVEYDIIGGNGGSKFHVEKSIIGPKSPGEVVGNLVLRSNLDREGCPSYQLIILASDHGSPXLTSTATISITVL X\n",
      "624 YQVNEDARVNQEVVRVSVTDXDSGKNGEVNVTLEGGDGFFSMKYDAVLSESLIYVGRPLDRETHPNFILTASCSDNGSPPLSTKQSFKINV X\n"
     ]
    }
   ],
   "source": [
    "for batch in all_batches:\n",
    "    for seq in batch:\n",
    "        for res in seq:\n",
    "            if res not in AA_alphabet:\n",
    "                print(i, seq, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[18,  6, 18,  ...,  0,  0,  0],\n",
       "        [13,  6,  2,  ...,  0,  0,  0],\n",
       "        [ 7, 13,  9,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [18, 15,  9,  ..., 19, 16,  0],\n",
       "        [18, 15,  0,  ...,  0,  0,  0],\n",
       "        [ 2, 19, 19,  ...,  0,  0,  0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForProteinFolding were not initialized from the model checkpoint at facebook/esmfold_v1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForProteinFolding(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 2560, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 2560, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-35): 36 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (key): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (value): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=1440, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (esm_s_mlp): Sequential(\n",
       "    (0): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (embedding): Embedding(23, 1024, padding_idx=0)\n",
       "  (trunk): EsmFoldingTrunk(\n",
       "    (pairwise_positional_embedding): EsmFoldRelativePosition(\n",
       "      (embedding): Embedding(66, 128)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-47): 48 x EsmFoldTriangularSelfAttentionBlock(\n",
       "        (layernorm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (sequence_to_pair): EsmFoldSequenceToPair(\n",
       "          (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (proj): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (pair_to_sequence): EsmFoldPairToSequence(\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "        )\n",
       "        (seq_attention): EsmFoldSelfAttention(\n",
       "          (proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (g_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (tri_mul_out): EsmFoldTriangleMultiplicativeUpdate(\n",
       "          (linear_a_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_a_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_b_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_b_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_z): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (layer_norm_in): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm_out): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (tri_mul_in): EsmFoldTriangleMultiplicativeUpdate(\n",
       "          (linear_a_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_a_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_b_p): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_b_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_z): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "          (layer_norm_in): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm_out): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (tri_att_start): EsmFoldTriangleAttention(\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear): EsmFoldLinear(in_features=128, out_features=4, bias=False)\n",
       "          (mha): EsmFoldAttention(\n",
       "            (linear_q): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_k): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_v): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_o): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (tri_att_end): EsmFoldTriangleAttention(\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear): EsmFoldLinear(in_features=128, out_features=4, bias=False)\n",
       "          (mha): EsmFoldAttention(\n",
       "            (linear_q): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_k): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_v): EsmFoldLinear(in_features=128, out_features=128, bias=False)\n",
       "            (linear_o): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (linear_g): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp_seq): EsmFoldResidueMLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp_pair): EsmFoldResidueMLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (4): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (drop): Dropout(p=0, inplace=False)\n",
       "        (row_drop): EsmFoldDropout(\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (col_drop): EsmFoldDropout(\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (recycle_s_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (recycle_z_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (recycle_disto): Embedding(15, 128)\n",
       "    (structure_module): EsmFoldStructureModule(\n",
       "      (layer_norm_s): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_z): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_in): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
       "      (ipa): EsmFoldInvariantPointAttention(\n",
       "        (linear_q): EsmFoldLinear(in_features=384, out_features=192, bias=True)\n",
       "        (linear_kv): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
       "        (linear_q_points): EsmFoldLinear(in_features=384, out_features=144, bias=True)\n",
       "        (linear_kv_points): EsmFoldLinear(in_features=384, out_features=432, bias=True)\n",
       "        (linear_b): EsmFoldLinear(in_features=128, out_features=12, bias=True)\n",
       "        (linear_out): EsmFoldLinear(in_features=2112, out_features=384, bias=True)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "      )\n",
       "      (ipa_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_ipa): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (transition): EsmFoldStructureModuleTransition(\n",
       "        (layers): ModuleList(\n",
       "          (0): EsmFoldStructureModuleTransitionLayer(\n",
       "            (linear_1): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
       "            (linear_2): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
       "            (linear_3): EsmFoldLinear(in_features=384, out_features=384, bias=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (bb_update): EsmFoldBackboneUpdate(\n",
       "        (linear): EsmFoldLinear(in_features=384, out_features=6, bias=True)\n",
       "      )\n",
       "      (angle_resnet): EsmFoldAngleResnet(\n",
       "        (linear_in): EsmFoldLinear(in_features=384, out_features=128, bias=True)\n",
       "        (linear_initial): EsmFoldLinear(in_features=384, out_features=128, bias=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x EsmFoldAngleResnetBlock(\n",
       "            (linear_1): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (linear_2): EsmFoldLinear(in_features=128, out_features=128, bias=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (linear_out): EsmFoldLinear(in_features=128, out_features=14, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (trunk2sm_s): Linear(in_features=1024, out_features=384, bias=True)\n",
       "    (trunk2sm_z): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (distogram_head): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (ptm_head): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lm_head): Linear(in_features=1024, out_features=23, bias=True)\n",
       "  (lddt_head): Sequential(\n",
       "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): Linear(in_features=128, out_features=1850, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EsmForProteinFolding.from_pretrained(ESM_FOLD)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = esmfold_tokenizer(\n",
    "            ['A'*2],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.esm_inference import parse_output\n",
    "parse_output(out, ['A'*2])[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
